{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Eigen- and Singular Value Decompositions\"\n",
    "subtitle: Advanced Statistical Computing\n",
    "author: Joong-Ho Won\n",
    "date: today\n",
    "date-format: \"MMMM YYYY\"\n",
    "institute: Seoul National University\n",
    "execute:\n",
    "  echo: true  \n",
    "format:\n",
    "  revealjs:\n",
    "    toc: false\n",
    "    theme: dark\n",
    "    code-fold: false   \n",
    "    scrollable: true    \n",
    "jupyter: julia    \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Julia Version 1.9.3\n",
      "Commit bed2cd540a1 (2023-08-24 14:43 UTC)\n",
      "Build Info:\n",
      "  Official https://julialang.org/ release\n",
      "Platform Info:\n",
      "  OS: macOS (x86_64-apple-darwin22.4.0)\n",
      "  CPU: 8 × Intel(R) Core(TM) i5-8279U CPU @ 2.40GHz\n",
      "  WORD_SIZE: 64\n",
      "  LIBM: libopenlibm\n",
      "  LLVM: libLLVM-14.0.6 (ORCJIT, skylake)\n",
      "  Threads: 2 on 8 virtual cores\n"
     ]
    }
   ],
   "source": [
    "versioninfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Dropbox/class/M1399.000200/2023/M1300_000200-2023fall/lectures/13-eigsvd`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1mStatus\u001b[22m\u001b[39m `~/Dropbox/class/M1399.000200/2023/M1300_000200-2023fall/lectures/13-eigsvd/Project.toml`\n",
      "  \u001b[90m[7d9fca2a] \u001b[39mArpack v0.5.4\n",
      "  \u001b[90m[6e4b80f9] \u001b[39mBenchmarkTools v1.3.2\n",
      "  \u001b[90m[b51810bb] \u001b[39mMatrixDepot v1.0.11\n",
      "  \u001b[90m[b8865327] \u001b[39mUnicodePlots v3.6.0\n",
      "  \u001b[90m[2f01184e] \u001b[39mSparseArrays\n"
     ]
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(pwd())\n",
    "Pkg.instantiate()\n",
    "Pkg.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "* We already saw wide applications of QR decomposition in least squares problem and solving square and underdetermined system of linear equations. \n",
    "\n",
    "* EVD and SVD can be deemed as more thorough orthogonalization of a matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Review: Eigenvalue Decomposition\n",
    "\n",
    "* Eigenvalue decomposition (EVD): $\\mathbf{A} = \\mathbf{X} \\Lambda \\mathbf{X}^{-1}$.\n",
    "    * $\\Lambda = \\text{diag}(\\lambda_1,\\ldots,\\lambda_n)$ collects the eigenvalues of $\\mathbf{A}$.\n",
    "    * Columns of $\\mathbf{X}$ are the eigenvectors.\n",
    "    \n",
    "* Not all matrices have EVD:\n",
    "$$\n",
    "\\mathbf{A} = \\begin{bmatrix} 2 & 1 & 0 \\\\ 0 & 2 & 1 \\\\ 0 & 0 & 2 \\end{bmatrix}\n",
    "$$\n",
    "has only a single independent eigenvector $\\mathbf{e}_1 = (1, 0, 0)^T$ associated with the multiple eigenvalue 2.\n",
    "\n",
    "---\n",
    "\n",
    "* In most statistical applications, we deal with eigenvalues/eigenvectors of symmetric matrices. \n",
    "The eigenvalues and eigenvectors of a real **symmetric** matrix are real.\n",
    "\n",
    "* **Eigenvalue decompostion of a symmetric matrix**: $\\mathbf{A} = \\mathbf{U} \\Lambda \\mathbf{U}^T$, where\n",
    "    * $\\Lambda = \\text{diag}(\\lambda_1,\\ldots,\\lambda_n)$\n",
    "    * columns of $\\mathbf{U}$ are the eigenvectors, which are (or can be chosen to be) mutually orthonormal. Thus $\\mathbf{U}$ is an orthogonal matrix.\n",
    "\n",
    "* A real symmetric matrix is positive semidefinite (positive definite) if and only if all eigenvalues are nonnegative (positive).\n",
    "\n",
    "---\n",
    "\n",
    "* **Schur decomposition**: *every* square matrix $\\mathbf{A}$ can be decomposed $\\mathbf{A} = \\mathbf{Q}\\mathbf{T}\\mathbf{Q}^*$\n",
    "    - $\\mathbf{T}$ is upper triangular, with eigenvalues on the diagonal.\n",
    "    - $\\mathbf{Q}$ is unitary: $\\mathbf{Q}^*\\mathbf{Q} = \\mathbf{I}$.\n",
    "    - Columns of $\\mathbf{Q}$ form a sequence of nested invariant spaces with respect to $\\mathbf{A}$: let $\\mathbf{Q} = [\\mathbf{q}_1 | \\dotsb | \\mathbf{q}_n ]$. Then $\\text{span}(\\mathbf{q}_1, \\dotsc, \\mathbf{q}_k) = \\text{span}(\\mathbf{A}\\mathbf{q}_1, \\dotsc, \\mathbf{A}\\mathbf{q}_k)$.\n",
    "\n",
    "* **Spectral radius** $\\rho(\\mathbf{A}) = \\max_i |\\lambda_i|$.\n",
    "\n",
    "* If $\\mathbf{A} \\in \\mathbb{R}^{n \\times n}$ a square matrix (not necessarily symmetric), then $\\text{tr}(\\mathbf{A}) = \\sum_i \\lambda_i$ and $\\det(\\mathbf{A}) = \\prod_i \\lambda_i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Review: Singular Value Decomposition\n",
    "\n",
    "* For a rectangular matrix $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$, let $p = \\min\\{m,n\\}$, then we have the SVD\n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U} \\Sigma \\mathbf{V}^T,\n",
    "$$\n",
    "where\n",
    "    * $\\mathbf{U} = (\\mathbf{u}_1,\\ldots,\\mathbf{u}_m) \\in \\mathbb{R}^{m \\times m}$ is orthogonal, i.e. $\\mathbf{U}^T\\mathbf{U} = \\mathbf{U}\\mathbf{U}^T = \\mathbf{I}_m$.\n",
    "    * $\\mathbf{V} = (\\mathbf{v}_1,\\ldots,\\mathbf{v}_n) \\in \\mathbb{R}^{n \\times n}$ is orthogonal, i.e. $\\mathbf{V}^T\\mathbf{V} = \\mathbf{V}\\mathbf{V}^T = \\mathbf{I}_n$.\n",
    "    * $\\Sigma = [\\text{diag}(\\sigma_1, \\ldots, \\sigma_p)~\\mathbf{0}]~\\text{or}~[\\text{diag}(\\sigma_1, \\ldots, \\sigma_p); \\mathbf{0}] \\in \\mathbb{R}^{m \\times n}$, $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_p \\ge 0$.  \n",
    "$\\sigma_i$ are called the **singular values**, $\\mathbf{u}_i$ are the **left singular vectors**, and $\\mathbf{v}_i$ are the **right singular vectors**.\n",
    "\n",
    "---\n",
    "\n",
    "* **Thin/skinny SVD**. Assume $m \\ge n$. $\\mathbf{A}$ can be factored as \n",
    "$$\n",
    "\\mathbf{A} = \\mathbf{U}_n \\Sigma_n \\mathbf{V}^T = \\sum_{i=1}^n \\sigma_i \\mathbf{u}_i \\mathbf{v}_i^T,\n",
    "$$ \n",
    "where \n",
    "    * $\\mathbf{U}_n \\in \\mathbb{R}^{m \\times n}$, $\\mathbf{U}_n^T \\mathbf{U}_n = \\mathbf{I}_n$\n",
    "    * $\\mathbf{V} \\in \\mathbb{R}^{n \\times n}$, $\\mathbf{V}^T \\mathbf{V} = \\mathbf{V} \\mathbf{V}^T \\mathbf{I}_n$\n",
    "    * $\\Sigma_n = \\text{diag}(\\sigma_1,\\ldots,\\sigma_n) \\in \\mathbb{R}^{n \\times n}$, $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_n \\ge 0$\n",
    "\n",
    "---\n",
    "\n",
    "* Denote $\\sigma(\\mathbf{A})=(\\sigma_1,\\ldots,\\sigma_p)^T$. Then \n",
    "    * $r = \\text{rank}(\\mathbf{A}) = \\# \\text{ nonzero singular values} = \\|\\sigma(\\mathbf{A})\\|_0$  \n",
    "    * $\\mathbf{A} = \\mathbf{U}_r \\Sigma_r \\mathbf{V}_r^T = \\sum_{i=1}^r \\sigma_i \\mathbf{u}_i \\mathbf{v}_i^T$\n",
    "    * $\\|\\mathbf{A}\\|_{\\text{F}} = (\\sum_{i=1}^p \\sigma_i^2)^{1/2} = \\|\\sigma(\\mathbf{A})\\|_2$\n",
    "    * $\\|\\mathbf{A}\\|_2 = \\sigma_1 = \\|\\sigma(\\mathbf{A})\\|_\\infty$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relation between EVD and SVD\n",
    "\n",
    "* Using thin SVD, $\\mathbf{A}^T \\mathbf{A} = \\mathbf{V} \\Sigma^2 \\mathbf{V}^T$ and $\\mathbf{A} \\mathbf{A}^T = \\mathbf{U} \\Sigma^2 \\mathbf{U}^T$.\n",
    "    + In principle we can obtain SVD of $\\mathbf{A}$ by doing two EVDs.\n",
    "\n",
    "* In fact, using thin SVD,\n",
    "$$\n",
    "\\small\n",
    "\t\\begin{bmatrix} \\mathbf{0}_{n \\times n} & \\mathbf{A}^T \\\\ \\mathbf{A} & \\mathbf{0}_{m \\times m} \\end{bmatrix} \n",
    "    = \\frac{1}{\\sqrt 2} \n",
    "    \\begin{bmatrix} \\mathbf{V} & \\mathbf{V} \\\\ \\mathbf{U} & -\\mathbf{U} \\end{bmatrix} \n",
    "    \\begin{bmatrix} \\Sigma & \\mathbf{0}_{n \\times n} \\\\ \\mathbf{0}_{n \\times n} & - \\Sigma \\end{bmatrix} \n",
    "    \\frac{1}{\\sqrt 2} \n",
    "    \\begin{bmatrix} \\mathbf{V}^T & \\mathbf{U}^T \\\\ \\mathbf{V}^T & - \\mathbf{U}^T \\end{bmatrix}.\n",
    "$$\n",
    "Hence any *symmetric* EVD solver can produce the SVD of a matrix $\\mathbf{A}$ without forming $\\mathbf{A} \\mathbf{A}^T$ or $\\mathbf{A}^T \\mathbf{A}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applications of EVD and SVD\n",
    "\n",
    "\n",
    "### 1. Principal Components Analysis\n",
    "\n",
    "* $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ is a centered data matrix. \n",
    "\n",
    "* Perform SVD $\\mathbf{X} = \\mathbf{U} \\Sigma \\mathbf{V}^T$ or equivalently eigendecomposition $\\mathbf{X}^T \\mathbf{X} = \\mathbf{V} \\Sigma^2 \\mathbf{V}^T$. The linear combinations $\\tilde{\\mathbf{x}}_i = \\mathbf{X} \\mathbf{v}_i$ are the **principal components** (PC) and have variance $\\sigma_i^2$.\n",
    "\n",
    "* Dimension reduction: reduce dimensionality $p$ to $q \\ll p$. Use top PCs $\\tilde{\\mathbf{x}}_1, \\ldots, \\tilde{\\mathbf{x}}_q$ in visualization and downstream analysis.\n",
    "\n",
    "---\n",
    "\n",
    "![[Genes mirror geography within Europe](https://doi.org/10.1038/nature07331) by Novembre et al., *Nature* 456,  98--101 (2008)](./novembre-nature.jpg){width=400}\n",
    "\n",
    "---\n",
    "\n",
    "* Use PCs to adjust for confounding --- a serious issue in association studies with large data sets.\n",
    "    * Use of PCA to adjust for confounding in modern genetic studies is proposed in the paper [Principal components analysis corrects for stratification in genome-wide association studies](https://doi.org/10.1038/ng1847) by Price, A., Patterson, N., Plenge, R. et al., _Nature Genetics_ 38, 904--909 (2006). It has been cited 6970 times as of Oct 30, 2023.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2. Low rank approximation\n",
    "\n",
    "* Goal: Find a low rank approximation of data matrix $\\mathbf{X}$ in, e.g., image/data compression. \n",
    "\n",
    "\n",
    "**Eckart-Young theorem**: \n",
    "$$\n",
    "\\min_{\\text{rank}(\\mathbf{Y})=r} \\|\\mathbf{X} - \\mathbf{Y} \\|_{\\text{F}}^2\n",
    "$$\n",
    "is achieved by $\\mathbf{Y} = \\sum_{i=1}^r \\sigma_i \\mathbf{u}_i \\mathbf{v}_i^T$ with optimal value $\\sum_{i=r}^{p} \\sigma_i^2$, where $(\\sigma_i, \\mathbf{u}_i, \\mathbf{v}_i)$ are singular values and vectors of $\\mathbf{X}$.\n",
    "\n",
    "---\n",
    "\n",
    "* [Gene Golub](https://en.wikipedia.org/wiki/Gene_H._Golub)'s $897 \\times 598$ picture requires $3 \\times 897 \\times 598 \\times 8 = 12,873,744$ bytes (3 RGB channels).  \n",
    "\n",
    "<img src=\"https://www.mathworks.com/content/mathworks/www/en/company/newsletters/articles/professor-svd/_jcr_content/mainParsys/columns/3/image_7.img.jpg/1490211663024.jpg\" width=\"150\" align=\"center\"/>\n",
    "\n",
    "* Rank 50 approximation requires $3 \\times 50 \\times (897 + 598) \\times 8 = 1,794,000$ bytes. \n",
    "\n",
    "<img src=\"https://www.mathworks.com/content/mathworks/www/en/company/newsletters/articles/professor-svd/_jcr_content/mainParsys/columns/2/image_6.img.jpg/1490211662986.jpg\" width=\"150\" align=\"center\"/>\n",
    "\n",
    "* Rank 12 approximation requires $12 \\times (2691+598) \\times 8 = 430,560$ bytes.\n",
    "\n",
    "<img src=\"https://www.mathworks.com/content/mathworks/www/en/company/newsletters/articles/professor-svd/_jcr_content/mainParsys/columns/1/image_5.img.jpg/1490211662955.jpg\" width=\"150\" align=\"center\"/>\n",
    "\n",
    "Source: [Professor SVD](https://www.mathworks.com/company/newsletters/articles/professor-svd.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Moore-Penrose (MP) pseudoinverse\n",
    "\n",
    "* MP pseudoinverse of a rectangular matrix $\\mathbf{A}$ is defined as a matrix $\\mathbf{A}^{\\dagger}$ such that\n",
    "    1. $\\mathbf{A}\\mathbf{A}^{\\dagger}\\mathbf{A} = \\mathbf{A}$;\n",
    "    2. $\\mathbf{A}^{\\dagger}\\mathbf{A}\\mathbf{A}^{\\dagger} = \\mathbf{A}^{\\dagger}$;\n",
    "    3. $(\\mathbf{A}\\mathbf{A}^{\\dagger})^T = \\mathbf{A}\\mathbf{A}^{\\dagger}$;\n",
    "    4. $(\\mathbf{A}^{\\dagger}\\mathbf{A})^T = \\mathbf{A}^{\\dagger}\\mathbf{A}$.\n",
    "\n",
    "---\n",
    "\n",
    "* Using thin SVD, \n",
    "$$\n",
    "\\mathbf{A}^{\\dagger} = \\mathbf{V} \\Sigma^{\\dagger} \\mathbf{U}^T,\n",
    "$$\n",
    "where $\\Sigma^{\\dagger} = \\text{diag}(\\sigma_1^{-1}, \\ldots, \\sigma_r^{-1}, 0, \\ldots, 0)$, $r= \\text{rank}(\\mathbf{A})$. This is how the [`pinv`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.pinv) function is implemented in Julia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×5 Matrix{Float64}:\n",
       " -0.0968407  -0.340739    0.479724  -0.217847  0.183095\n",
       " -0.330339   -0.0637448  -0.455237  -0.23351   0.222205\n",
       "  0.190843    0.187126    0.378086   0.507667  0.178208"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random, LinearAlgebra\n",
    "Random.seed!(280)\n",
    "X = randn(5, 3)\n",
    "pinv(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "pinv(A::<b>AbstractMatrix{T}</b>; <i>atol, rtol</i>)<i> where T</i> in LinearAlgebra at <a href=\"file:///Users/julia/.julia/scratchspaces/a66863c6-20e8-4ff4-8a62-49f30b1f605e/agent-cache/default-grannysmith-C07ZQ07RJYVY.0/build/default-grannysmith-C07ZQ07RJYVY-0/julialang/julia-release-1-dot-9/usr/share/julia/stdlib/v1.9/LinearAlgebra/src/dense.jl\" target=\"_blank\">/Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/dense.jl:1469</a>"
      ],
      "text/plain": [
       "pinv(\u001b[90mA\u001b[39m::\u001b[1mAbstractMatrix\u001b[22m\u001b[0m{T}; atol, rtol) where T\n",
       "\u001b[90m     @\u001b[39m \u001b[90mLinearAlgebra\u001b[39m \u001b[90m/Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/\u001b[39m\u001b[90m\u001b[4mdense.jl:1469\u001b[24m\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculation of Moore-Penrose inverse by SVD\n",
    "@which pinv(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 4. Least squares via SVD\n",
    "\n",
    "* When $\\mathbf{X}$ does not have full column rank, the Moore-Penrose pseudoinverse gives the minimum $\\ell_2$ norm solution to OLS (recall Lecture Notes on Linear Regression). \n",
    "\n",
    "* To see this, let $\\mathbf{X} = \\sum_{i=1}^{\\min(n,p)}\\sigma_i\\mathbf{u}_i\\mathbf{v}_i^T$ (full SVD) , $r=\\text{rank}(\\mathbf{X})$ and $\\mathbf{\\beta} = \\sum_{j=1}^p \\alpha_j\\mathbf{v}_j$.\n",
    "\n",
    "$$\n",
    "\\small\n",
    "\\begin{split}\n",
    "    \\|\\mathbf{y} - \\mathbf{X}\\beta\\|_2^2 &= \\|\\mathbf{y} - \\mathbf{U}\\Sigma_p\\mathbf{V}^T\\beta\\|_2^2 \\\\\n",
    "    &= \\|\\sum_{i=1}^n(\\mathbf{u}_i^T\\mathbf{y})\\mathbf{u}_i - \\sum_{i=1}^{\\min(n,p)}\\sigma_i\\alpha_i\\mathbf{u}_i\\|_2^2\n",
    "    = \\|\\sum_{i=1}^n(\\mathbf{u}_i^T\\mathbf{y} - \\sigma_i\\alpha_i)\\mathbf{u}_i\\|_2^2\n",
    "    = \\sum_{i=1}^n(\\mathbf{u}_i^T\\mathbf{y} - \\sigma_i\\alpha_i)^2\n",
    "    \\\\\n",
    "    &= \\sum_{i=1}^r(\\mathbf{u}_i^T\\mathbf{y} - \\sigma_i\\alpha_i)^2 + \\sum_{i=r+1}^n(\\mathbf{u}_i^T\\mathbf{y})^2\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "  Thus $\\hat{\\alpha}_j = \\frac{1}{\\sigma_j}\\mathbf{u}_j^T\\mathbf{y}$ for $j=1,\\dotsc, r$ but is arbitrary for $j>r$. The minimum $\\ell_2$ norm solution is given by setting $\\hat{\\alpha}_j=0$ for $j>r$, resulting in\n",
    "\n",
    "$$\n",
    "\\small\n",
    "    \\hat\\beta = \\sum_{j=1}^r\\frac{\\mathbf{u}_j^T\\mathbf{y}}{\\sigma_j}\\mathbf{v}_j = \\mathbf{X}^{\\dagger}\\mathbf{y}\n",
    "$$\n",
    "  \n",
    "  and\n",
    "$$\n",
    "\\small\n",
    "\\begin{eqnarray*}\n",
    "\t\\widehat{\\mathbf{y}} &=& \\mathbf{X} \\widehat \\beta = \\mathbf{U}_r \\mathbf{U}_r^T \\mathbf{y}.\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "\n",
    "  In general, SVD is more expensive than other approaches (Cholesky, QR). In some applications, SVD is computed for other purposes. Then, we get least squares solution for free."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Ridge regression\n",
    "\n",
    "* In ridge regression, we minimize\n",
    "$$\n",
    "\\small\n",
    "\t\\|\\mathbf{y} - \\mathbf{X} \\beta\\|_2^2 + \\lambda \\|\\beta\\|_2^2,\n",
    "$$\n",
    "where $\\lambda$ is a tuning parameter.\n",
    "\n",
    "* Ridge regression by augmented linear regression: Ridge regression problem is equivalent to\n",
    "$$\n",
    "\\small\n",
    "\t\\left\\| \\begin{pmatrix} \\mathbf{y} \\\\ \\mathbf{0}_p \\end{pmatrix} - \\begin{pmatrix}\n",
    "\t\\mathbf{X} \\\\ \\sqrt \\lambda \\mathbf{I}_p\n",
    "\t\\end{pmatrix} \\beta \\right\\|_2^2.\n",
    "$$\n",
    "Therefore any methods for linear regression (e.g., LSQR) can be applied.\n",
    "\n",
    "* Ridge regression by method of normal equation: The normal equation for the ridge problem is\n",
    "$$\n",
    "\\small\n",
    "\t(\\mathbf{X}^T \\mathbf{X} + \\lambda \\mathbf{I}_p) \\beta = \\mathbf{X}^T \\mathbf{y}.\n",
    "$$\n",
    "Therefore Cholesky decomposition can be used.\n",
    "\n",
    "---\n",
    "\n",
    "* Ridge regression by SVD: If we obtain the (thin) SVD of $\\mathbf{X}$\n",
    "$$\n",
    "\\small\n",
    "\t\\mathbf{X} = \\mathbf{U} \\Sigma_{p} \\mathbf{V}^T,\n",
    "$$\n",
    "then the normal equation reads\n",
    "$$\n",
    "\\small\n",
    "\t\\mathbf{V}^T(\\Sigma^2 + \\lambda \\mathbf{I}_p) \\mathbf{V}^T \\beta = \\mathbf{V}^T\\Sigma \\mathbf{U}^T \\mathbf{y}.\n",
    "$$\n",
    "\n",
    "  We get\n",
    "$$\n",
    "\\small\n",
    "\t\\widehat \\beta (\\lambda) = \\mathbf{V} (\\Sigma^2 + \\lambda \\mathbf{I}_p)^{-1}\\Sigma \\mathbf{U}^T \\mathbf{y} =\n",
    "    \\sum_{i=1}^p \\frac{\\sigma_i \\mathbf{u}_i^T \\mathbf{y}}{\\sigma_i^2 + \\lambda} \\mathbf{v}_i = \\sum_{i=1}^r \\frac{\\sigma_i \\mathbf{u}_i^T \\mathbf{y}}{\\sigma_i^2 + \\lambda} \\mathbf{v}_i, \\quad r = \\text{rank}(\\mathbf{X}).\n",
    "$$\n",
    "\n",
    "* It is clear that \n",
    "$$\n",
    "\\small\n",
    "\\begin{eqnarray*}\n",
    "\t\\lim_{\\lambda \\to 0} \\widehat \\beta (\\lambda) = \\mathbf{X}^{\\dagger}\\mathbf{y},\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "the minimum $\\ell_2$ norm solution,\n",
    "and $\\|\\widehat \\beta (\\lambda)\\|_2$ is monotone decreasing as $\\lambda$ increases.\n",
    "\n",
    "* Only *one* SVD is needed for all $\\lambda$, in contrast to the method of augmented linear regression or Cholesky."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms for EVD\n",
    "\n",
    "> **Any EVD solver must be iterative.**\n",
    "\n",
    "* Abel (1824) showed that the real root of a polynomial of degree 5 or more with rational coefficients cannot be written using any expression involving rational numbers, addtion, subtraction, multiplication, division, and $k$th roots.\n",
    "\n",
    "* This means that no algorithm can produce the exact roots of the characteristic polynomial of a matrix, i.e., eigenvalues, in a finite number of steps.\n",
    "\n",
    "* \"Direct\" EVD solver refers to a solver that reduces to a general matrix to a special form in finite flops, and then apply iterative methods that converges to EVD.\n",
    "\n",
    "* For ease of exposition, we restrict attention to real symmetric matrices, i.e., we assume $\\mathbf{A}=\\mathbf{A}^T \\in \\mathbb{R}^{n \\times n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### One eigen-pair: power iteration\n",
    "\n",
    "* Iterates according to\n",
    "$$\n",
    "\\small\n",
    "\\begin{eqnarray*}\n",
    "\t\\mathbf{x}^{(t)} &\\gets& \\frac{1}{\\|\\mathbf{A} \\mathbf{x}^{(t-1)}\\|} \\mathbf{A} \\mathbf{x}^{(t-1)}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "from an initial guess $\\mathbf{x}^{(0)}$ of *unit norm*.\n",
    "\n",
    "* Obviously, $\\mathbf{x}^{(t)} \\propto \\mathbf{A}^t \\mathbf{x}^{(0)}$, hence the name. (We normalize so that $\\Vert \\mathbf{x}^{(t)} \\Vert = 1$).\n",
    "\n",
    "* Suppose we arrange eigenvalues $|\\lambda_1| > |\\lambda_2| \\ge \\cdots \\ge |\\lambda_n|$ (the first inequality strict) with corresponding eigenvectors $\\mathbf{u}_i$, and expand $\\mathbf{x}^{(0)} = c_1 \\mathbf{u}_1 + \\cdots + c_n \\mathbf{u}_n$, then\n",
    "$$\n",
    "\\small\n",
    "\\begin{eqnarray*}\n",
    "\t\\mathbf{x}^{(t)} &=& \\frac{\\left( \\sum_i \\lambda_i^t \\mathbf{u}_i \\mathbf{u}_i^T \\right) \\left( \\sum_i c_i \\mathbf{u}_i \\right)}{\\|\\left( \\sum_i \\lambda_i^t \\mathbf{u}_i \\mathbf{u}_i^T \\right) \\left( \\sum_i c_i \\mathbf{u}_i \\right)\\|} \\\\\n",
    "\t&=& \\frac{\\sum_i c_i \\lambda_i^t \\mathbf{u}_i}{\\|\\sum_i c_i \\lambda_i^t \\mathbf{u}_i\\|}\t\\\\\n",
    "\t&=& \\frac{c_1 \\mathbf{u}_1 + c_2 (\\lambda_2/\\lambda_1)^t \\mathbf{u}_2 + \\cdots + c_n (\\lambda_n/\\lambda_1)^t \\mathbf{u}_n}{\\|c_1 \\mathbf{u}_1 + c_2 (\\lambda_2/\\lambda_1)^t \\mathbf{u}_2 + \\cdots + c_n (\\lambda_n/\\lambda_1)^t \\mathbf{u}_n\\|} \\left( \\frac{\\lambda_1}{|\\lambda_1|} \\right)^t.\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "Thus $\\mathbf{x}^{(t)}/\\left( \\frac{\\lambda_1}{|\\lambda_1|} \\right)^t \\to \\frac{c_1}{|c_1|}\\mathbf{u}_1$ as $t \\to \\infty$. The convergence rate is $|\\lambda_2|/|\\lambda_1|$ (**linear/geometric convergence**).\n",
    "\n",
    "* $\\lambda_1^{(t)} = \\mathbf{x}^{(t)T} \\mathbf{A} \\mathbf{x}^{(t)}$ converges to $\\lambda_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eigen{Float64, Float64, Matrix{Float64}, Vector{Float64}}\n",
       "values:\n",
       "5-element Vector{Float64}:\n",
       " -3.5582775705641994\n",
       " -1.424888979702748\n",
       "  0.4093807500562252\n",
       "  1.8475495594338596\n",
       "  3.0216689122421685\n",
       "vectors:\n",
       "5×5 Matrix{Float64}:\n",
       "  0.591789   0.420034   0.116011  -0.492886  -0.465792\n",
       "  0.474641  -0.502806  -0.247432  -0.420409   0.532856\n",
       " -0.573199  -0.228009  -0.320981  -0.628095  -0.349173\n",
       "  0.186207   0.173967  -0.897576   0.318546  -0.167173\n",
       " -0.247532   0.698931  -0.129021  -0.29042    0.59096"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random, LinearAlgebra\n",
    "Random.seed!(280)\n",
    "n = 5\n",
    "A = Symmetric(randn(n, n), :U)\n",
    "Aeig = eigen(A)  # we basically want to know how this function works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.6115814215958305, 0.45090483674776094, -0.5573886487276638, 0.19333280629676475, -0.2731177644080751], -3.545712335129104)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# power iteration\n",
    "x = randn(n)  # random initialization\n",
    "normalize!(x)\n",
    "for t=1:20\n",
    "    x .= A * x\n",
    "    normalize!(x)\n",
    "end\n",
    "(x, dot(x, A * x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Variants of power iteration\n",
    "\n",
    "* Inverse iteration: Apply power iteration to $\\mathbf{A}^{-1}$ to find the eigen-pair of smallest *absolute* value. (May pre-compute LU or Cholesky of $\\mathbf{A}$).\n",
    "\n",
    "* Shifted inverse iteration: Apply power iteration to $(\\mathbf{A}-\\mu\\mathbf{I})^{-1}$ to find the eigen-pair of closed to $\\mu$.\n",
    "    + Converges linearly to an eigenvalue close to the pre-specified $\\mu$.\n",
    "\n",
    "* Rayleigh quotient iteration: Substitute the shift $\\mu$ in shifted inverse iteration with Rayleigh quotient $\\mathbf{v}^{(t) T}\\mathbf{A}\\mathbf{v}^{(t)}/\\mathbf{v}^{(t) T}\\mathbf{v}^{(t)}$.\n",
    "    + Converges *cubically* to the eigen-pair closest to $\\mathbf{v}^{(0)}$.\n",
    "\n",
    "* Example: PageRank problem seeks top left eigenvector of transition matrix $\\mathbf{P}$ and costs $O(n)$ per iteration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Top $r$ eigen-pairs: orthogonal iteration \n",
    "\n",
    "= simultaneous iteration, *block* power iteration\n",
    "\n",
    "#### Motivation\n",
    "\n",
    "* Rewrite the power method: \n",
    "$$\n",
    "\\begin{eqnarray*}\n",
    "    \\mathbf{z}^{(t)} &\\gets& \\mathbf{A} \\mathbf{x}^{(t-1)} \\\\\n",
    "\t(\\mathbf{x}^{(t)}, \\Vert \\mathbf{z}^{(t)}\\Vert) &\\gets& \\texttt{qr}(\\mathbf{z}^{(t)}) \\quad (\\|\\mathbf{z}^{(t)}\\|\\mathbf{x}^{(t)} = \\mathbf{z}^{(t)})\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "The second step is the first iteration of the Gram-Schmidt QR.\n",
    "\n",
    "---\n",
    "\n",
    "#### Algorithm  \n",
    "\n",
    "1. Initialize $\\tilde{\\mathbf{Q}}^{(0)} \\in \\mathbb{R}^{n \\times r}$ with orthonormal columns\n",
    "2. For $t=1,2,\\ldots$, \n",
    "    a. $\\mathbf{Z}^{(t)} \\gets \\mathbf{A} \\tilde{\\mathbf{Q}}^{(t-1)}$  \n",
    "    b. $(\\tilde{\\mathbf{Q}}^{(t)}, \\tilde{\\mathbf{R}}^{(t)}) \\gets \\texttt{qr}(\\mathbf{Z}^{(t)})$ (reduced QR)\n",
    "\n",
    "<!--* If we did not *orthonormalize* $\\mathbf{Z}^{(t)}$, then we would have had $\\mathbf{Z}^{(t)} = \\mathbf{A}^t \\mathbf{Z}^{(0)}$ with $\\mathbf{Z}^{(0)} = \\tilde{\\mathbf{Q}}^{(0)}$. Thus orthogonal iteration is a generalization of the power method to a higher dimensional invariant subspace.\n",
    "\n",
    "* Note, for each $t$, $\\text{col}(\\mathbf{Z}^{(t)}) = \\text{col}(\\tilde{\\mathbf{Q}}^{(t)})$.\n",
    "\n",
    "* Orthonormalization (QR decompsition) is to prevent ill-conditioning of $\\mathbf{Z}^{(t)}$ under finite precision.-->\n",
    "\n",
    "* Orthogonal iteration is a generalization of the power method to a higher dimensional invariant subspace.\n",
    "\n",
    "* It can be shown $\\tilde{\\mathbf{Q}}^{(t)}$ converges to the eigenspace of the largest $r$ eigenvalues if they are real and separated from remaining spectrum. The convergence rate is $\\max_{k=1,\\dotsc,r}|\\lambda_{k+1}|/|\\lambda_k|$.\n",
    "\n",
    "---\n",
    "\n",
    "* To see that orthogonal iteration is a generalization of the power method, observe that\n",
    "$$\n",
    "\\small\n",
    "\\begin{aligned}\n",
    "    \\mathbf{A}\\tilde{\\mathbf{Q}}^{(0)} &= \\mathbf{Z}^{(1)} = \\tilde{\\mathbf{Q}}^{(1)}\\hat{\\mathbf{R}}^{(1)}, \\quad \\hat{\\mathbf{R}}^{(1)} = \\tilde{\\mathbf{R}}^{(1)} \\\\\n",
    "    \\mathbf{A}^2\\tilde{\\mathbf{Q}}^{(0)} &= (\\mathbf{A}\\tilde{\\mathbf{Q}}^{(1)})\\hat{\\mathbf{R}}^{(1)} \\\\\n",
    "                                         &= \\mathbf{Z}^{(2)}\\hat{\\mathbf{R}}^{(1)} = \\tilde{\\mathbf{Q}}^{(2)}\\tilde{\\mathbf{R}}^{(2)}\\hat{\\mathbf{R}}^{(1)} = \\tilde{\\mathbf{Q}}^{(2)}\\hat{\\mathbf{R}}^{(2)} \\\\\n",
    "    \\mathbf{A}^3\\tilde{\\mathbf{Q}}^{(0)} &= (\\mathbf{A}\\tilde{\\mathbf{Q}}^{(2)})\\hat{\\mathbf{R}}^{(2)} \\\\\n",
    "                                         &= \\mathbf{Z}^{(3)}\\hat{\\mathbf{R}}^{(2)} = \\tilde{\\mathbf{Q}}^{(3)}\\tilde{\\mathbf{R}}^{(3)}\\hat{\\mathbf{R}}^{(2)} = \\tilde{\\mathbf{Q}}^{(3)}\\hat{\\mathbf{R}}^{(3)}  \\\\\n",
    "                                         & \\vdots\n",
    "\\end{aligned}\n",
    "$$\n",
    "So,\n",
    "$$\n",
    "\\small\n",
    "    \\mathbf{A}^t\\tilde{\\mathbf{Q}}^{(0)} = \\mathbf{Z}^{(t)}\\hat{\\mathbf{R}}^{(t-1)} = \\tilde{\\mathbf{Q}}^{(t)}\\hat{\\mathbf{R}}^{(t)},\n",
    "    \\quad\n",
    "    \\hat{\\mathbf{R}}^{(t)} = \\tilde{\\mathbf{R}}^{(t)} \\tilde{\\mathbf{R}}^{(t-1)} \\dotsb \\tilde{\\mathbf{R}}^{(1)}\n",
    "    .\n",
    "$$\n",
    "\n",
    "* Since $\\hat{\\mathbf{R}}^{(t)}$ is upper triangular (why?), $\\tilde{\\mathbf{Q}}^{(t)}\\hat{\\mathbf{R}}^{(t)}$ is the reduced QR decomposition of $\\mathbf{A}^t\\tilde{\\mathbf{Q}}^{(0)}$, and $\\tilde{\\mathbf{Q}}^{(t)}$ is orthonormal basis of $\\text{col}(\\mathbf{A}^t\\tilde{\\mathbf{Q}}^{(0)})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Full EVD ($r=n$): QR iteration\n",
    "\n",
    "#### Algorithm {.smaller} \n",
    "\n",
    "1. $\\mathbf{A}^{(0)} \\gets \\mathbf{A}$\n",
    "2. For $t=1,2,\\ldots$, \n",
    "    a. $(\\mathbf{Q}^{(t)}, \\mathbf{R}^{(t)}) \\gets \\texttt{qr}(\\mathbf{A}^{(t-1)})$    (full QR)\n",
    "    b. $\\mathbf{A}^{(t)} \\gets \\mathbf{R}^{(t)}\\mathbf{Q}^{(t)}$\n",
    "\n",
    "---\n",
    "\n",
    "#### Explanation {.smaller}\n",
    "\n",
    "* It can be shown that QR iteration is equivalent to the orthogonal iteration on $\\mathbf{A}$ starting with $\\mathbf{Q}^{(0)}=\\mathbf{I}_n$. Specifically,\n",
    "$$\n",
    "\\small\n",
    "\\begin{split}\n",
    "    \\tilde{\\mathbf{R}}^{(t)} &= \\mathbf{R}^{(t)} \\\\\n",
    "    \\tilde{\\mathbf{Q}}^{(t)} &= \\mathbf{Q}^{(1)} \\mathbf{Q}^{(2)} \\dotsb \\mathbf{Q}^{(t)} \\\\\n",
    "    \\mathbf{A}^{(t)} &= (\\tilde{\\mathbf{Q}}^{(t)})^T\\mathbf{A}\\tilde{\\mathbf{Q}}^{(t)}\n",
    "    .\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "* Also note that\n",
    "$$\n",
    "\\small\n",
    "    \\mathbf{A}^t = \\tilde{\\mathbf{Q}}^{(t)}\\hat{\\mathbf{R}}^{(t)}\n",
    "    .\n",
    "$$\n",
    "\n",
    "*  Take $r=n$ in the orthogonal iteration. Then $\\tilde{\\mathbf{Q}}^{(t)}$ converges to $\\mathbf{U}$ up to sign changes. This implies that\n",
    "$$\n",
    "\\small\n",
    "\t\\mathbf{A}^{(t)} = (\\tilde{\\mathbf{Q}}^{(t)})^T \\mathbf{A} \\tilde{\\mathbf{Q}}^{(t)}\n",
    "$$\n",
    "converges to a diagonal form $\\boldsymbol{\\Lambda} = \\text{diag}(\\lambda_1, \\ldots, \\lambda_n)$.\n",
    "\n",
    "* *Linear* convergence rate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### QR iteration with shifts\n",
    "\n",
    "#### Algorithm {.smaller}\n",
    "\n",
    "1. $\\mathbf{A}^{(0)} \\gets \\mathbf{A}$\n",
    "2. For $t=1,2,\\ldots$, \n",
    "    a. Pick a shift $\\mu_t$  (e.g., $\\mu_t = \\mathbf{A}_{nn}^{(t)}$)\n",
    "    b. $(\\mathbf{Q}^{(t)}, \\mathbf{R}^{(t)}) \\gets \\texttt{qr}(\\mathbf{A}^{(t-1)} - \\mu_t\\mathbf{I})$\n",
    "    c. $\\mathbf{A}^{(t)} \\gets \\mathbf{R}^{(t)}\\mathbf{Q}^{(t)} + \\mu_t\\mathbf{I}$\n",
    "\n",
    "\n",
    "* Can be shown to be equivalent to simultaneous shifted *inverse* iteration starting with\n",
    "$$\n",
    "\\mathbf{Q}^{(0)} = \\mathbf{P} = \\begin{bmatrix}  &  &  & 1 \\\\ & & 1 & \\\\ & \\dotsc & & \\\\ 1 & & & \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "* $\\mu_t = \\mathbf{A}_{nn}^{(t)}$ is a good choice for the shift (and free to compute!), with **cubic** convergence (cf. Rayleigh quotient shift)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Practical QR iteration\n",
    "\n",
    "* Implemented in LAPACK: used by Julia, Matlab, R.\n",
    "\n",
    "* General QR iteration is expensive: $O(n^3)$ per iteration.\n",
    "\n",
    "* Tridiagonalization (by Householder) + implicit shifted QR iteration on the tridiagonal matrix.\n",
    "   1. Direct phase: Householder tridiagonalization: $4n^3/3$ for eigenvalues only, $8n^3/3$ for both eigenvalues and eigenvectors. (Why can't we apply Householder to make it diagonal directly?) \n",
    "   \n",
    "---\n",
    "\n",
    "$$\n",
    "\\small\n",
    "\\mathbf{Q}_1^T\\mathbf{A} = \n",
    "\\begin{bmatrix} \n",
    "\\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} \\\\ \n",
    "0 & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times}  \\\\\n",
    "0 & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} \\\\\n",
    "0 & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} \\\\\n",
    "0 & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times}\n",
    "\\end{bmatrix} \n",
    "%\n",
    "\\rightarrow\n",
    "%\n",
    "\\mathbf{Q}_1^T\\mathbf{A}\\mathbf{Q}_1 = \n",
    "\\begin{bmatrix} \n",
    "\\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} \\\\ \n",
    "\\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times}  \\\\\n",
    "\\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} \\\\\n",
    "\\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} \\\\\n",
    "\\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times}\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "  vs.\n",
    "$$\n",
    "\\small\n",
    "\\mathbf{Q}_1^T\\mathbf{A} = \n",
    "\\begin{bmatrix} \n",
    "\\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} \\\\ \n",
    "\\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times}  \\\\\n",
    "0 & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} \\\\\n",
    "0 & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} \\\\\n",
    "0 & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times}\n",
    "\\end{bmatrix} \n",
    "%\n",
    "\\rightarrow\n",
    "%\n",
    "\\mathbf{Q}_1^T\\mathbf{A}\\mathbf{Q}_1 = \n",
    "\\begin{bmatrix} \n",
    "\\boldsymbol{\\times} & \\boldsymbol{\\times} & 0 & 0 & 0 \\\\ \n",
    "\\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times}  \\\\\n",
    "0 & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} \\\\\n",
    "0 & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} \\\\\n",
    "0 & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times} & \\boldsymbol{\\times}\n",
    "\\end{bmatrix} \n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "   2. Iterative phase: Built on QR iteration with shifts. Tridiangonal structure allows the QR decomposition cheap (\"implicit Q theorem\"). On average 1.3-1.6 QR iteration per eigenvalue, $\\sim 20n$ flops per iteration. So total operation count is about $30n^2$. Eigenvectors need an extra of about $6n^3$ flops.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "| Phase                  | Eigenvalue   | Eigenvector |\n",
    "|------------------------|--------------|-------------|\n",
    "| Tridiagonal reduction  | $4n^3/3$     | + $4n^3/3$    |\n",
    "| implicit shifted QR    | $\\sim 30n^2$ | + $\\sim 6n^3$ |\n",
    "\n",
    "\n",
    "* Take-home message: **Don't request eigenvectors unless necessary**. Use [`eigvals`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.eigvals) in Julia to request only eigenvalues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Unsymmetric EVD\n",
    "\n",
    "* Reduction to the upper Hessenberg form (upper triangular + subdiagonal)\n",
    "\n",
    "* The **unsymmetric QR algorithm** obtains the real Schur decomposition of the Hessenberg matrix.\n",
    "    - Implicit Q theorem still applies, but more expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Example\n",
    "\n",
    "Julia functions: [`eigen`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.eigen), [`eigen!`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.eigen!), [`eigvals`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.eigvals!), [`eigvecs`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.eigvecs), [`eigmax`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.eigmax), [`eigmin`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.eigmin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Eigen{Float64, Float64, Matrix{Float64}, Vector{Float64}}\n",
       "values:\n",
       "5-element Vector{Float64}:\n",
       " -3.5582775705641994\n",
       " -1.424888979702748\n",
       "  0.4093807500562252\n",
       "  1.8475495594338596\n",
       "  3.0216689122421685\n",
       "vectors:\n",
       "5×5 Matrix{Float64}:\n",
       "  0.591789   0.420034   0.116011  -0.492886  -0.465792\n",
       "  0.474641  -0.502806  -0.247432  -0.420409   0.532856\n",
       " -0.573199  -0.228009  -0.320981  -0.628095  -0.349173\n",
       "  0.186207   0.173967  -0.897576   0.318546  -0.167173\n",
       " -0.247532   0.698931  -0.129021  -0.29042    0.59096"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(280)\n",
    "A = Symmetric(randn(5, 5), :U)\n",
    "Aeig = eigen(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " -3.5582775705641994\n",
       " -1.424888979702748\n",
       "  0.4093807500562252\n",
       "  1.8475495594338596\n",
       "  3.0216689122421685"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eigenvalues\n",
    "Aeig.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Matrix{Float64}:\n",
       "  0.591789   0.420034   0.116011  -0.492886  -0.465792\n",
       "  0.474641  -0.502806  -0.247432  -0.420409   0.532856\n",
       " -0.573199  -0.228009  -0.320981  -0.628095  -0.349173\n",
       "  0.186207   0.173967  -0.897576   0.318546  -0.167173\n",
       " -0.247532   0.698931  -0.129021  -0.29042    0.59096"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eigenvectors\n",
    "Aeig.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×5 Matrix{Float64}:\n",
       "  0.0139273  0.0291782  0.292971  -0.39582   -0.215047\n",
       "  0.0291782  0.09844    0.271352   0.477086   0.527932\n",
       "  0.292971   0.271352   0.376726   0.672617   0.203571\n",
       " -0.39582    0.477086   0.672617   2.00114    0.127733\n",
       " -0.215047   0.527932   0.203571   0.127733  -0.158166"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inversion by EVD\n",
    "inv(Aeig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "inv(A::<b>Eigen</b>) in LinearAlgebra at <a href=\"file:///Users/julia/.julia/scratchspaces/a66863c6-20e8-4ff4-8a62-49f30b1f605e/agent-cache/default-grannysmith-C07ZQ07RJYVY.0/build/default-grannysmith-C07ZQ07RJYVY-0/julialang/julia-release-1-dot-9/usr/share/julia/stdlib/v1.9/LinearAlgebra/src/eigen.jl\" target=\"_blank\">/Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/eigen.jl:436</a>"
      ],
      "text/plain": [
       "inv(\u001b[90mA\u001b[39m::\u001b[1mEigen\u001b[22m)\n",
       "\u001b[90m     @\u001b[39m \u001b[90mLinearAlgebra\u001b[39m \u001b[90m/Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/\u001b[39m\u001b[90m\u001b[4meigen.jl:436\u001b[24m\u001b[39m"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which inv(Aeig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.5875398687018"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determinant by EVD\n",
    "det(Aeig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "det(A::<b>Eigen</b>) in LinearAlgebra at <a href=\"file:///Users/julia/.julia/scratchspaces/a66863c6-20e8-4ff4-8a62-49f30b1f605e/agent-cache/default-grannysmith-C07ZQ07RJYVY.0/build/default-grannysmith-C07ZQ07RJYVY-0/julialang/julia-release-1-dot-9/usr/share/julia/stdlib/v1.9/LinearAlgebra/src/eigen.jl\" target=\"_blank\">/Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/eigen.jl:437</a>"
      ],
      "text/plain": [
       "det(\u001b[90mA\u001b[39m::\u001b[1mEigen\u001b[22m)\n",
       "\u001b[90m     @\u001b[39m \u001b[90mLinearAlgebra\u001b[39m \u001b[90m/Applications/Julia-1.9.app/Contents/Resources/julia/share/julia/stdlib/v1.9/LinearAlgebra/src/\u001b[39m\u001b[90m\u001b[4meigen.jl:437\u001b[24m\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@which det(Aeig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " -3.5582775705642056\n",
       " -1.4248889797027493\n",
       "  0.40938075005622393\n",
       "  1.847549559433859\n",
       "  3.021668912242168"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigvals(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.021668912242168"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigmax(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3.558277570564205"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigmin(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Don't request eigenvectors unless needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000×1000 Symmetric{Float64, Matrix{Float64}}:\n",
       " -0.387613    0.830797     0.731869   …   0.0438502   0.39227   -1.73985\n",
       "  0.830797    0.798861    -1.2226        -0.152364    0.348436  -1.53224\n",
       "  0.731869   -1.2226       0.712162       0.338267   -0.406531   0.303491\n",
       "  1.63481     2.28494     -0.688582       0.924935    0.814725   1.21108\n",
       " -1.83127     0.809969     0.0938082     -1.18017     0.800359  -0.555267\n",
       "  0.911476    0.532963     0.0581193  …   0.798043    1.92928    0.653282\n",
       " -1.08284    -0.39067     -1.93781        0.560661   -0.857352  -1.49901\n",
       "  1.61787     1.98693     -0.766486      -0.622425   -1.16277    2.00806\n",
       "  1.77062     0.0125561   -0.708909      -1.27664    -1.51582    0.189037\n",
       " -0.365245    0.665422     0.659153       0.310974    0.69347   -0.328191\n",
       " -0.331965    0.925945     0.237316   …  -0.740832    0.535047   1.46116\n",
       " -0.697962   -1.16414      1.78832       -0.107645    1.23204    1.10244\n",
       " -0.2055     -0.350213     0.730864      -1.50582     1.28053    0.185578\n",
       "  ⋮                                   ⋱                         \n",
       " -1.33994    -0.207696     0.276488       0.0702686   0.474359  -1.90014\n",
       " -0.0506158   0.381956     1.2497         2.45185    -0.577832  -0.087702\n",
       "  0.486985    1.5383      -0.890526   …   0.477043   -2.06086    0.745614\n",
       " -1.07223     1.14012      0.969375      -0.591605    0.907349  -0.0105815\n",
       "  1.46845     0.981375    -1.36146       -0.742225    1.39159    1.26403\n",
       " -0.113087    0.261022    -0.0422322     -0.0115979  -0.666856   0.657904\n",
       "  2.41368     1.2471      -0.908807      -0.59915     1.58512    1.93124\n",
       "  1.49221    -0.00478031   1.01257    …   2.18865    -0.144515   0.108744\n",
       "  0.217292    0.023727    -0.937259       1.05869     0.537121   1.02429\n",
       "  0.0438502  -0.152364     0.338267      -0.466739   -0.648593  -0.24912\n",
       "  0.39227     0.348436    -0.406531      -0.648593    2.51402    0.582001\n",
       " -1.73985    -1.53224      0.303491      -0.24912     0.582001  -2.29198"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using BenchmarkTools, Random, LinearAlgebra\n",
    "\n",
    "Random.seed!(280)\n",
    "n = 1000\n",
    "A = Symmetric(randn(n, n), :U)  # build from the upper triangular part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 102 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m41.617 ms\u001b[22m\u001b[39m … \u001b[35m70.308 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 6.26%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m48.271 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m49.115 ms\u001b[22m\u001b[39m ± \u001b[32m 5.018 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m1.41% ± 2.83%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m▁\u001b[39m \u001b[39m▃\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m█\u001b[34m \u001b[39m\u001b[39m \u001b[32m▆\u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▄\u001b[39m▁\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m▇\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[34m▇\u001b[39m\u001b[39m▇\u001b[32m█\u001b[39m\u001b[39m▄\u001b[39m▇\u001b[39m▇\u001b[39m▄\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m▆\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m \u001b[39m▄\n",
       "  41.6 ms\u001b[90m         Histogram: frequency by time\u001b[39m        67.1 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m7.99 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m11\u001b[39m."
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requesting eigenvalues only is cheaper\n",
    "@benchmark eigvals($A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 27 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m176.221 ms\u001b[22m\u001b[39m … \u001b[35m213.026 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 1.51%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m186.644 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m190.981 ms\u001b[22m\u001b[39m ± \u001b[32m 13.316 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.74% ± 0.80%\n",
       "\n",
       "  \u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[34m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▃\u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▇\u001b[39m▇\u001b[34m▇\u001b[39m\u001b[39m▇\u001b[39m▁\u001b[39m▁\u001b[39m▇\u001b[39m▇\u001b[39m▇\u001b[39m▁\u001b[32m▁\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▇\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▇\u001b[39m▁\u001b[39m▇\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▇\u001b[39m▇\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▇\u001b[39m▁\u001b[39m▇\u001b[39m▁\u001b[39m▁\u001b[39m▇\u001b[39m█\u001b[39m \u001b[39m▁\n",
       "  176 ms\u001b[90m           Histogram: frequency by time\u001b[39m          213 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m23.25 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m13\u001b[39m."
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requesting eigenvectors requires extra work\n",
    "@benchmark eigen($A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 27 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m174.911 ms\u001b[22m\u001b[39m … \u001b[35m339.120 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 1.17%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m179.500 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m188.660 ms\u001b[22m\u001b[39m ± \u001b[32m 32.140 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.76% ± 0.81%\n",
       "\n",
       "  \u001b[39m█\u001b[39m▆\u001b[34m▁\u001b[39m\u001b[39m \u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▆\u001b[39m▁\u001b[32m▇\u001b[39m\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m \u001b[39m▁\n",
       "  175 ms\u001b[90m           Histogram: frequency by time\u001b[39m          339 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m23.25 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m13\u001b[39m."
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark eigvecs($A)  # same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm for SVD\n",
    "\n",
    "Assume $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ and we seek the SVD $\\mathbf{A} = \\mathbf{U} \\mathbf{D} \\mathbf{V}^T$. \n",
    "\n",
    "\n",
    "### Golub-Kahan-Reinsch algorithm\n",
    "\n",
    "* Stage 1: Transform $\\mathbf{A}$ to an upper bidiagonal form $\\mathbf{B}$ (by Householder).  \n",
    "\n",
    "![Bidiagonalization](./svd_bidiagonalization.png){width=400}\n",
    "\n",
    "---\n",
    "\n",
    "![Bidiagonalization 2](./SVD_bidiagonalization_2.png){width=400}\n",
    "    \n",
    "* Stage 2: Apply implicit shifted QR iteration to the tridiagonal matrix $\\mathbf{B}^T\\mathbf{B}$ *without explicitly forming it*. That is, $\\mathbf{B}^{(t)}$ is *directly* formed from $\\mathbf{B}^{(t-1)}$.\n",
    "\n",
    "\n",
    "* $4m^2 n + 8mn^2 + 9n^3$ flops for a tall $(m \\ge n)$ matrix.\n",
    "\n",
    "---\n",
    "\n",
    "### Example\n",
    "\n",
    "Julia functions: [`svd`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.svd), [`svd!`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.svd), [`svdvals`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.svdvals), [`svdvals!`](https://docs.julialang.org/en/v1/stdlib/LinearAlgebra/#LinearAlgebra.svdvals!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVD{Float64, Float64, Matrix{Float64}, Vector{Float64}}\n",
       "U factor:\n",
       "5×3 Matrix{Float64}:\n",
       " -0.380998    0.214814  -0.38012\n",
       "  0.0761273   0.570332  -0.1334\n",
       " -0.0902045  -0.577001  -0.736322\n",
       "  0.343699    0.498341  -0.543378\n",
       "  0.850164   -0.217489  -0.0168563\n",
       "singular values:\n",
       "3-element Vector{Float64}:\n",
       " 2.772161439329863\n",
       " 1.5236100184747268\n",
       " 1.1153222145932091\n",
       "Vt factor:\n",
       "3×3 Matrix{Float64}:\n",
       "  0.134368   0.750489    0.647079\n",
       " -0.975601  -0.0142296   0.21909\n",
       " -0.173633   0.66073    -0.730266"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(280)\n",
    "\n",
    "A = randn(5, 3)\n",
    "Asvd = svd(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5×3 Matrix{Float64}:\n",
       " -0.380998    0.214814  -0.38012\n",
       "  0.0761273   0.570332  -0.1334\n",
       " -0.0902045  -0.577001  -0.736322\n",
       "  0.343699    0.498341  -0.543378\n",
       "  0.850164   -0.217489  -0.0168563"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Asvd.U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       "  0.134368   0.750489    0.647079\n",
       " -0.975601  -0.0142296   0.21909\n",
       " -0.173633   0.66073    -0.730266"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vt is cheaper to extract than V\n",
    "Asvd.Vt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 adjoint(::Matrix{Float64}) with eltype Float64:\n",
       " 0.134368  -0.975601   -0.173633\n",
       " 0.750489  -0.0142296   0.66073\n",
       " 0.647079   0.21909    -0.730266"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Asvd.V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " 2.772161439329863\n",
       " 1.5236100184747268\n",
       " 1.1153222145932091"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Asvd.S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Don't request singular vectors unless needed.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 127 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m35.415 ms\u001b[22m\u001b[39m … \u001b[35m49.818 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m38.556 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m39.411 ms\u001b[22m\u001b[39m ± \u001b[32m 3.157 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.97% ± 2.85%\n",
       "\n",
       "  \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▃\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▃\u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▄\u001b[39m \u001b[39m█\u001b[39m▃\u001b[34m▃\u001b[39m\u001b[39m▃\u001b[39m▁\u001b[39m \u001b[32m \u001b[39m\u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m▇\u001b[39m▄\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[32m▆\u001b[39m\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▄\u001b[39m█\u001b[39m▄\u001b[39m▆\u001b[39m▄\u001b[39m█\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m▄\u001b[39m▆\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m \u001b[39m▄\n",
       "  35.4 ms\u001b[90m         Histogram: frequency by time\u001b[39m        47.2 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m4.11 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m9\u001b[39m."
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Random.seed!(280)\n",
    "\n",
    "n, p = 1000, 500\n",
    "A = randn(n, p)\n",
    "@benchmark svdvals(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 59 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m72.871 ms\u001b[22m\u001b[39m … \u001b[35m103.514 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 3.23%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m82.671 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m86.051 ms\u001b[22m\u001b[39m ± \u001b[32m  9.452 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m1.44% ± 1.89%\n",
       "\n",
       "  \u001b[39m▁\u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▄\u001b[39m▄\u001b[39m \u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m█\u001b[34m \u001b[39m\u001b[39m█\u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m▁\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m \u001b[39m \n",
       "  \u001b[39m█\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m▁\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m█\u001b[34m▆\u001b[39m\u001b[39m█\u001b[39m▆\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[32m▁\u001b[39m\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▆\u001b[39m▁\u001b[39m█\u001b[39m▆\u001b[39m▁\u001b[39m█\u001b[39m▁\u001b[39m▁\u001b[39m▆\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m \u001b[39m▁\n",
       "  72.9 ms\u001b[90m         Histogram: frequency by time\u001b[39m          103 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m17.23 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m12\u001b[39m."
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark svd(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobi's method for symmetric EVD\n",
    "\n",
    "* One of the oldest ideas for computing eigenvalues, by [Jacobi](https://en.wikipedia.org/wiki/Carl_Gustav_Jacob_Jacobi) in 1845.\n",
    "\n",
    "Assume $\\mathbf{A} \\in \\mathbf{R}^{n \\times n}$ is symmetric and we seek the EVD of $\\mathbf{A} = \\mathbf{U} \\Lambda \\mathbf{U}^T$.\n",
    "\n",
    "* Idea: diagonalize a 2x2 matrix by similarity transform using an orthogonal matrix:\n",
    "\n",
    "$$\n",
    "\\small\n",
    "    \\begin{bmatrix} c & -s \\\\ s & c \\end{bmatrix}\n",
    "    \\begin{bmatrix} a & d  \\\\ d & b \\end{bmatrix}\n",
    "    \\begin{bmatrix} c & s \\\\ -s & c \\end{bmatrix}\n",
    "    =\n",
    "    \\begin{bmatrix} * & 0 \\\\ 0 & * \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "  It can be easily seen that $c=\\cos\\theta$ and $s=\\sin\\theta$ satisifies \n",
    "$$\n",
    "\\small\n",
    "    \\tan(2\\theta) = \\frac{2d}{b-a}\n",
    "$$\n",
    "if $a\\neq b$, otherwise $c=s=1/\\sqrt{2}$.\n",
    "\n",
    "---\n",
    "\n",
    "* We can systematically reduce off-diagonal entries of $\\mathbf{A}$\n",
    "$$\n",
    "\\small\n",
    "\\text{off}(\\mathbf{A}) = \\sum_i \\sum_{j \\ne i} a_{ij}^2\n",
    "$$\n",
    "by Jacobi/Givens rotations:\n",
    "$$\n",
    "\\small\n",
    "\\begin{eqnarray*}\n",
    "\t\\mathbf{J}(p,q,\\theta) = \\begin{bmatrix} \n",
    "\t1 & & 0 & & 0 & & 0 \\\\\n",
    "\t\\vdots & \\ddots & \\vdots & & \\vdots & & \\vdots \\\\\n",
    "\t0 & & \\cos(\\theta) & & \\sin(\\theta) & & 0 \\\\ \n",
    "\t\\vdots & & \\vdots & \\ddots & \\vdots & & \\vdots \\\\\n",
    "\t0 & & - \\sin(\\theta) & & \\cos(\\theta) & & 0 \\\\\n",
    "\t\\vdots & & \\vdots & & \\vdots & \\ddots & \\vdots \\\\\n",
    "\t0 & & 0 & & 0 & & 1 \\end{bmatrix}\n",
    "    .\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "$\\mathbf{J}(p,q,\\theta)$ is orthogonal.\n",
    "\n",
    "---\n",
    "\n",
    "* Consider $\\mathbf{B} = \\mathbf{J}^T \\mathbf{A} \\mathbf{J}$. $\\mathbf{B}$ preserves the symmetry and eigenvalues of $\\mathbf{A}$. Taking \n",
    "$$\n",
    "\\small\n",
    "\\begin{eqnarray*}\n",
    "\\begin{cases}\n",
    "\\tan (2\\theta) = 2a_{pq}/({a_{qq}-a_{pp}}) & \\text{if } a_{pp} \\ne a_{qq} \\\\\n",
    "\\theta = \\pi/4 & \\text{if } a_{pp}=a_{qq}\n",
    "\\end{cases}\n",
    "\\end{eqnarray*}\n",
    "$$\n",
    "forces $b_{pq}=0$.\n",
    "\n",
    "* Since orthogonal transform preserves Frobenius norm, we have\n",
    "$$\n",
    "\\small\n",
    "b_{pp}^2 + b_{qq}^2 = a_{pp}^2 + a_{qq}^2 + 2a_{pq}^2.\n",
    "$$ \n",
    "\n",
    "* Since $\\|\\mathbf{A}\\|_{\\text{F}} = \\|\\mathbf{B}\\|_{\\text{F}}$, \n",
    "$$\n",
    "\\small\n",
    "\\begin{split}\n",
    "\\|\\mathbf{B}\\|_{\\text{F}}^2 &= \\text{off}(\\mathbf{B}) + \\|\\text{diag}(B)\\|_2^2  \\\\\n",
    "    &= \\text{off}(\\mathbf{B}) + \\|\\text{diag}(A)\\|_2^2  + 2a_{pq}^2\n",
    "    &= \\text{off}(\\mathbf{A}) + \\|\\text{diag}(A)\\|_2^2 \n",
    "    &= \\|\\mathbf{A}\\|_{\\text{F}}^2\n",
    "\\end{split}\n",
    "$$\n",
    "or\n",
    "$$\n",
    "\\small\n",
    "\t\\text{off}(\\mathbf{B}) = \\text{off}(\\mathbf{A}) - 2a_{pq}^2 < \\text{off}(\\mathbf{A})\n",
    "$$\n",
    "whenever $a_{pq} \\ne 0$.\n",
    "\n",
    "* One Jacobi rotation costs $O(n)$ flops.\n",
    "\n",
    "---\n",
    "\n",
    "* **Classical Jacobi**: search for the largest $|a_{ij}|$ at each iteration. $O(n^2)$ efforts!\n",
    "\n",
    "* $\\text{off}(\\mathbf{A}) \\le n(n-1) a_{ij}^2$ and $\\text{off}(\\mathbf{B}) = \\text{off}(\\mathbf{A}) - 2 a_{ij}^2$ together implies \n",
    "$$\n",
    "\\text{off}(\\mathbf{B}) \\le \\left( 1 - \\frac{2}{n(n-1)} \\right) \\text{off}(\\mathbf{A}).\n",
    "$$\n",
    "Thus Jacobi's method converges at least linearly.\n",
    "\n",
    "* In practice, cyclic-by-row implementation, to avoid the costly $O(n^2)$ search in the classical Jacobi.\n",
    "```Julia\n",
    "[J(p, q, theta) for p=1:n-1, q=p+1:n]\n",
    "```\n",
    "\n",
    "* Jacobi method attracts a lot recent attention because of its rich inherent parallelism (and does not need tridiagonal reduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krylov subspace methods for top eigen-pairs\n",
    "\n",
    "* State-of-art iterative methods for obtaining the top eigenvalues/vectors or singular values/vectors of large **sparse** or **structured** matrices.\n",
    "\n",
    "* Recall the PageRank problem. We want to find the top left eigenvector of the transition matrix $\\mathbf{P}$ of size $10^9$ by $10^9$. Direct methods such as (unsymmetric) QR or SVD takes forever. Iterative methods such as power method is feasible. However power method may take a large number of iterations.\n",
    "\n",
    "---\n",
    "\n",
    "#### Motivation\n",
    "\n",
    "* Recall the Rayleigh quotient\n",
    "$$\n",
    "    r(\\mathbf{x}) = \\frac{\\mathbf{x}^T\\mathbf{A}\\mathbf{x}}{\\mathbf{x}^T\\mathbf{x}}\n",
    "$$\n",
    "\n",
    "  Note $r(\\mathbf{u}_i) = \\lambda_i$.\n",
    "  \n",
    "* Suppose $\\mathbf{q}_1, \\dotsc, \\mathbf{q}_n$ form an orthonormal basis of $\\mathbb{R}^n$. Define\n",
    "$$\n",
    "    M_k \\triangleq \\max_{\\mathbf{u}\\in\\text{span}(\\mathbf{q}_1,\\dotsc,\\mathbf{q}_k)} r(\\mathbf{u}),\n",
    "    \\quad\n",
    "    \\text{and}\n",
    "    \\quad\n",
    "    m_k \\triangleq \\min_{\\mathbf{v}\\in\\text{span}(\\mathbf{q}_1,\\dotsc,\\mathbf{q}_k)} r(\\mathbf{v}).\n",
    "$$\n",
    "\n",
    "* Obviously\n",
    "$$\n",
    "\\begin{split}\n",
    "    M_1 &\\le M_2 \\le \\dotsb \\le M_n = \\lambda_1, \\\\\n",
    "    m_1 &\\ge m_2 \\ge \\dotsb \\ge m_n = \\lambda_n.\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "* The goal is to choose $\\mathbf{q}_1, \\mathbf{q}_2, \\dotsc$ so that $M_k \\approx \\lambda_1$.\n",
    "\n",
    "---\n",
    "\n",
    "* Consider the gradient of the Rayleigh quotient:\n",
    "$$\n",
    "    \\nabla r(\\mathbf{x}) = \\frac{2}{\\mathbf{x}^T\\mathbf{x}}(\\mathbf{A}\\mathbf{x} - r(\\mathbf{x})\\mathbf{x}).\n",
    "$$\n",
    "\n",
    "* Suppose $M_k = r(\\mathbf{v}_k)$ for some $\\mathbf{v}_k \\in \\text{span}(\\mathbf{q}_1,\\dotsc,\\mathbf{q}_k)$. If $\\nabla r(\\mathbf{v}_k) = 0$, we are done. Otherwise, it is reasonable to choose the next vector $\\mathbf{q}_{k+1}$ so that\n",
    "$$\n",
    "    \\nabla r(\\mathbf{v}_k) \\in \\text{span}(\\mathbf{q}_1,\\dotsc,\\mathbf{q}_k, \\mathbf{q}_{k+1})\n",
    "$$\n",
    "because $r(\\mathbf{x})$ increases steepest in this direction.\n",
    "\n",
    "* Since $\\nabla r(\\mathbf{v}_k) \\in \\text{span}(\\mathbf{x}, \\mathbf{A}\\mathbf{x})$, the above proposal is satisfied if\n",
    "$$\n",
    "    \\text{span}(\\mathbf{q}_1,\\dotsc,\\mathbf{q}_k) = \\text{span}(\\mathbf{q}_1, \\mathbf{A}\\mathbf{q}_1, \\dotsc, \\mathbf{A}^{k-1}\\mathbf{q}_1) = \\mathcal{K}^k(\\mathbf{A}, \\mathbf{q}_1).\n",
    "$$\n",
    "\n",
    "* Finding $\\mathbf{q}_1, \\mathbf{q}_2, \\dotsc$ amounts to computing orthonormal bases for $\\mathcal{K}^k(\\mathbf{A}, \\mathbf{q}_1)$ (Gram-Schmidt).\n",
    "\n",
    "* The eigenvalues of the $k\\times k$ matrix $\\mathbf{Q}_k^T\\mathbf{A}\\mathbf{Q}_k$ (either tridiagonal or upper Hessenberg), call the *Ritz values*, approximate the top $k$ eigenvalues of $\\mathbf{A}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### Instances\n",
    "\n",
    "* **Lanczos method**: top eigen-pairs of a large _symmetric_ matrix.  (Use tridiagonal reduction $\\mathbf{Q}^T\\mathbf{A}\\mathbf{Q} = \\mathbf{T}$.)\n",
    "\n",
    "* **Arnoldi method**: top eigen-pairs of a large _asymmetric_ matrix. (Use Hessenberg reduction $\\mathbf{Q}^T\\mathbf{A}\\mathbf{Q} = \\mathbf{H}$.)\n",
    "\n",
    "* Both methods are also adapted to obtain top singular values/vectors of large sparse or structured matrices.\n",
    "\n",
    "* `eigs` and `svds` in Julia [Arpack.jl](https://github.com/JuliaLinearAlgebra/Arpack.jl) package and Matlab are wrappers of the ARPACK package, which implements Lanczos and Arnoldi methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mverify download of index files...\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mreading database\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39madding metadata...\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39madding svd data...\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mwriting database\n",
      "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mused remote sites are sparse.tamu.edu with MAT index and math.nist.gov with HTML index\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "typeof(A) = SparseMatrixCSC{Float64, Int64}\n",
      "typeof(Afull) = Matrix{Float64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.06194756814290342"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using MatrixDepot, SparseArrays\n",
    "\n",
    "# Download the Boeing/bcsstk34 matrix (sparse, pd, 588-by-588) from SuiteSparse collection\n",
    "# https://sparse.tamu.edu/Boeing\n",
    "A = matrixdepot(\"Boeing/bcsstk34\")\n",
    "# Change type of A from Symmetric{Float64,SparseMatrixCSC{Float64,Int64}} to SparseMatrixCSC\n",
    "A = sparse(A)\n",
    "@show typeof(A)\n",
    "Afull = Matrix(A)\n",
    "@show typeof(Afull)\n",
    "# actual sparsity level\n",
    "count(!iszero, A) / length(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       \u001b[38;5;8m┌──────────────────────────────────────────┐\u001b[0m    \n",
       "     \u001b[38;5;8m1\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;5m⡿\u001b[0m\u001b[38;5;5m⣯\u001b[0m\u001b[38;5;5m⣭\u001b[0m\u001b[38;5;5m⠛\u001b[0m\u001b[38;5;5m⠳\u001b[0m\u001b[38;5;5m⢶\u001b[0m\u001b[38;5;5m⣀\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;1m> 0\u001b[0m\n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;5m⣧\u001b[0m\u001b[38;5;5m⠛\u001b[0m\u001b[38;5;5m⠿\u001b[0m\u001b[38;5;5m⣧\u001b[0m\u001b[38;5;5m⣄\u001b[0m\u001b[38;5;5m⠐\u001b[0m\u001b[38;5;5m⠿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;4m< 0\u001b[0m\n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m\u001b[38;5;5m⢹\u001b[0m\u001b[38;5;5m⣆\u001b[0m\u001b[38;5;5m⢀\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⢀\u001b[0m\u001b[38;5;5m⣠\u001b[0m\u001b[38;5;5m⡝\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⡆\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀\u001b[38;5;5m⠸\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣧\u001b[0m⠀\u001b[38;5;5m⣰\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⢀\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣭\u001b[0m\u001b[38;5;4m⠈\u001b[0m\u001b[38;5;5m⢛\u001b[0m\u001b[38;5;5m⡻\u001b[0m\u001b[38;5;5m⣮\u001b[0m\u001b[38;5;5m⡅\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⣻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠉\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣅\u001b[0m\u001b[38;5;5m⠉\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣍\u001b[0m\u001b[38;5;5m⠁\u001b[0m\u001b[38;5;5m⢹\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣾\u001b[0m\u001b[38;5;5m⠇\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣶\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠛\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣶\u001b[0m\u001b[38;5;5m⣜\u001b[0m\u001b[38;5;5m⠛\u001b[0m\u001b[38;5;5m⢻\u001b[0m\u001b[38;5;5m⣶\u001b[0m\u001b[38;5;5m⣤\u001b[0m\u001b[38;5;5m⡛\u001b[0m\u001b[38;5;5m⢻\u001b[0m\u001b[38;5;5m⣶\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣤\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣄\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠛\u001b[0m\u001b[38;5;5m⢻\u001b[0m\u001b[38;5;5m⣶\u001b[0m\u001b[38;5;5m⣄\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⢻\u001b[0m\u001b[38;5;5m⣶\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⠛\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣌\u001b[0m\u001b[38;5;5m⠛\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣤\u001b[0m\u001b[38;5;5m⡙\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣤\u001b[0m\u001b[38;5;5m⣄\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⠿\u001b[0m\u001b[38;5;5m⣧\u001b[0m\u001b[38;5;5m⣄\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⠿\u001b[0m\u001b[38;5;5m⣧\u001b[0m\u001b[38;5;5m⣤\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣄\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⠿\u001b[0m\u001b[38;5;5m⣧\u001b[0m\u001b[38;5;5m⣌\u001b[0m\u001b[38;5;5m⠛\u001b[0m\u001b[38;5;5m⠿\u001b[0m\u001b[38;5;5m⣧\u001b[0m\u001b[38;5;5m⣤\u001b[0m\u001b[38;5;5m⡙\u001b[0m\u001b[38;5;5m⠿\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣤\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣄\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣄\u001b[0m\u001b[38;5;5m⠘\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⡀\u001b[0m⠀⠀⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣇\u001b[0m\u001b[38;5;5m⣀\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣀\u001b[0m\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣀\u001b[0m\u001b[38;5;5m⣀\u001b[0m⠀⠀⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣄\u001b[0m\u001b[38;5;5m⠘\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣤\u001b[0m\u001b[38;5;5m⡀\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣤\u001b[0m\u001b[38;5;5m⣄\u001b[0m⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣷\u001b[0m⠀\u001b[38;5;5m⠻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m⠀⠀\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⢸\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m⠀⠀\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⢶\u001b[0m\u001b[38;5;5m⡄\u001b[0m⠀⠀\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "      \u001b[38;5;8m\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣷\u001b[0m\u001b[38;5;5m⣄\u001b[0m\u001b[38;5;5m⠘\u001b[0m\u001b[38;5;5m⠷\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣦\u001b[0m\u001b[38;5;5m⣠\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "   \u001b[38;5;8m588\u001b[0m \u001b[38;5;8m│\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;5m⠙\u001b[0m\u001b[38;5;5m⢿\u001b[0m\u001b[38;5;5m⣿\u001b[0m⠀⠀\u001b[38;5;5m⠈\u001b[0m\u001b[38;5;5m⣻\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;5m⣿\u001b[0m\u001b[38;5;8m│\u001b[0m \u001b[38;5;8m\u001b[0m   \n",
       "       \u001b[38;5;8m└──────────────────────────────────────────┘\u001b[0m    \n",
       "       ⠀\u001b[38;5;8m1\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m\u001b[0m⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀\u001b[38;5;8m588\u001b[0m⠀    \n",
       "       ⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀21 418 ≠ 0⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀⠀    "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using UnicodePlots\n",
    "spy(A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.016667 seconds (2.33 k allocations: 2.996 MiB, 35.13% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " 3.4642087294879e7\n",
       " 3.691680883205632e7\n",
       " 3.723096977158153e7\n",
       " 3.725598402633067e7\n",
       " 3.976762941994778e7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# top 5 eigenvalues by LAPACK (QR algorithm)\n",
    "n = size(A, 1)\n",
    "@time eigvals(Symmetric(Afull), (n-4):n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.215533 seconds (3.86 M allocations: 258.556 MiB, 4.99% gc time, 99.79% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([3.976762941994773e7, 3.725598402633051e7, 3.723096977158146e7, 3.691680883205639e7, 3.464208729487892e7], 5, 7, 101, [62452.22096265024, -319111.3479949276, -83967.9875361371, -96154.42640644909, 7248.436585979588, -65434.48311713214, 73352.37152493223, 98772.82719860655, -28367.39508102584, -27905.75642512194  …  563314.4050039607, 260043.3556216124, 27074.250039000308, 144975.7650049854, -105385.6629031659, 57703.187803609784, 19548.838518629484, -298438.9773246268, 32018.406730532402, -21586.23359059178])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Arpack\n",
    "# top 5 eigenvalues by iterative methods\n",
    "@time eigs(A; nev=5, ritzvec=false, which=:LM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 429 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m 8.948 ms\u001b[22m\u001b[39m … \u001b[35m41.729 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m10.437 ms              \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m11.643 ms\u001b[22m\u001b[39m ± \u001b[32m 3.907 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m3.10% ± 8.35%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m█\u001b[34m▆\u001b[39m\u001b[39m▄\u001b[39m \u001b[32m \u001b[39m\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \n",
       "  \u001b[39m▄\u001b[39m▁\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m▇\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▅\u001b[39m▁\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▅\u001b[39m▆\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▁\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m \u001b[39m▆\n",
       "  8.95 ms\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      30.9 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m2.85 MiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m14\u001b[39m."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark eigvals(Symmetric(Afull), (n-4):n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BenchmarkTools.Trial: 1599 samples with 1 evaluation.\n",
       " Range \u001b[90m(\u001b[39m\u001b[36m\u001b[1mmin\u001b[22m\u001b[39m … \u001b[35mmax\u001b[39m\u001b[90m):  \u001b[39m\u001b[36m\u001b[1m2.546 ms\u001b[22m\u001b[39m … \u001b[35m 12.305 ms\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmin … max\u001b[90m): \u001b[39m0.00% … 0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[34m\u001b[1mmedian\u001b[22m\u001b[39m\u001b[90m):     \u001b[39m\u001b[34m\u001b[1m3.034 ms               \u001b[22m\u001b[39m\u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmedian\u001b[90m):    \u001b[39m0.00%\n",
       " Time  \u001b[90m(\u001b[39m\u001b[32m\u001b[1mmean\u001b[22m\u001b[39m ± \u001b[32mσ\u001b[39m\u001b[90m):   \u001b[39m\u001b[32m\u001b[1m3.121 ms\u001b[22m\u001b[39m ± \u001b[32m499.116 μs\u001b[39m  \u001b[90m┊\u001b[39m GC \u001b[90m(\u001b[39mmean ± σ\u001b[90m):  \u001b[39m0.50% ± 3.44%\n",
       "\n",
       "  \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▂\u001b[39m▄\u001b[39m▆\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m▇\u001b[39m▆\u001b[32m▄\u001b[39m\u001b[39m▄\u001b[39m▃\u001b[39m▃\u001b[39m▂\u001b[39m▂\u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m \u001b[39m▁\n",
       "  \u001b[39m▅\u001b[39m▅\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▇\u001b[39m▄\u001b[39m▁\u001b[39m▇\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[34m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[32m█\u001b[39m\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m█\u001b[39m▆\u001b[39m▇\u001b[39m█\u001b[39m▇\u001b[39m▇\u001b[39m▆\u001b[39m▇\u001b[39m▇\u001b[39m▁\u001b[39m▄\u001b[39m▆\u001b[39m▄\u001b[39m▆\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▅\u001b[39m▅\u001b[39m▁\u001b[39m▅\u001b[39m▅\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▄\u001b[39m▁\u001b[39m▅\u001b[39m▁\u001b[39m▁\u001b[39m▅\u001b[39m \u001b[39m█\n",
       "  2.55 ms\u001b[90m      \u001b[39m\u001b[90mHistogram: \u001b[39m\u001b[90m\u001b[1mlog(\u001b[22m\u001b[39m\u001b[90mfrequency\u001b[39m\u001b[90m\u001b[1m)\u001b[22m\u001b[39m\u001b[90m by time\u001b[39m      4.57 ms \u001b[0m\u001b[1m<\u001b[22m\n",
       "\n",
       " Memory estimate\u001b[90m: \u001b[39m\u001b[33m146.33 KiB\u001b[39m, allocs estimate\u001b[90m: \u001b[39m\u001b[33m755\u001b[39m."
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@benchmark eigs($A; nev=5, ritzvec=false, which=:LM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see >1000 fold speedup in this case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further reading\n",
    "\n",
    "* [The QR algorithm](https://doi.org/10.1109/5992.814656) by Beresford N. Parlett.\n",
    "\n",
    "* Section 8.6 of [Matrix Computations](https://ucla.worldcat.org/title/matrix-computations/oclc/824733531&referer=brief_results) by Gene Golub and Charles Van Loan (2013)."
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.9.3",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.3"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "341px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "572px",
    "left": "0px",
    "right": "auto",
    "top": "106px",
    "width": "232px"
   },
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
